{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e8eba-3097-4740-a468-faf15d009eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a086b3a-2d50-4b27-ab49-ff751e27e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from hexdump import hexdump\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import time\n",
    "import math\n",
    "import text_to_image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2aa082d-6b88-4166-b270-d47fe25b770a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "284e8c8e-52fc-47fb-84e1-0e20f438f48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83a1e75c-8d7d-4ea5-9ee4-789a4dad60bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1afdde1a-43b7-4771-afb1-e6c1acdd2fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./track_b_learn.csv\", index_col = [0])\n",
    "label = pd.read_csv(\"./track_b_learn_label.csv\", index_col = [0])\n",
    "payload = train['payload']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1ff92b5-547b-4a67-a2e5-602b3323d879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80     4849\n",
       "68        3\n",
       "432       1\n",
       "951       1\n",
       "278       1\n",
       "Name: s_port, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['s_port'] <= 1024]['s_port'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8af2ab41-688a-4054-9ee4-b4f4f87f4580",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, label], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e104ace-23b4-4a88-b5c2-acc1e04313cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2_exploit           19691\n",
       "4_unknown           16089\n",
       "3_post              11718\n",
       "1_reconnaissance     2502\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "381d6b5e-2dc5-46b3-90ca-b7767a61c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_1d_to_2d(list, cols):\n",
    "    return [list[j:j + cols] for j in range(0, len(list), cols)]\n",
    "\n",
    "def preprocess(train):\n",
    "    if (len(train) != 0):\n",
    "        size = 100\n",
    "        payload_images = list(range(0,len(train)))\n",
    "        image_buff = np.zeros([len(train), size, size])\n",
    "        for id, idx in enumerate(train, start = 0):\n",
    "            ln = len(str(idx).encode('utf-8'))\n",
    "            wid = math.pow(ln, 0.5)\n",
    "            rem = ln%wid  # line 10\n",
    "            hex_payload = [alpha for alpha in str(idx)]\n",
    "            \n",
    "            for i in range(ln): # a -> array('B')\n",
    "                hex_payload[i] = hex_payload[i].encode('utf-8').hex()\n",
    "                hex_payload[i] = int(hex_payload[i], 16)\n",
    "            hex_payload = np.array(hex_payload)\n",
    "            grayscale = convert_1d_to_2d(hex_payload, int((ln/wid)))\n",
    "            grayscale = pd.DataFrame(grayscale)\n",
    "            gray_row = len(grayscale.index)\n",
    "            gray_col = len(grayscale.columns)\n",
    "            grayscale = pd.DataFrame(grayscale).fillna(0)\n",
    "            grayscale = np.pad(grayscale, ((0, size-gray_row), (0, size-gray_col)), 'constant', constant_values=0)\n",
    "            grayscale = grayscale.astype(np.uint8)\n",
    "            image_buff[id] = grayscale\n",
    "            \n",
    "    return image_buff\n",
    "\n",
    "def buff_to_grayscale_image(image_buff):\n",
    "    for i, row in enumerate(image_buff, start = 0):\n",
    "        grayscale_image = Image.fromarray(row, 'L')\n",
    "        grayscale_image.save(\"/Users/timkh/Desktop/kisa/contest/grayscale_class/1_reconnaissance/\" + str(i) + \".jpg\", \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82d2a38d-fd6b-4945-84c1-426884ae7912",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# image_buff = preprocess(payload)\n",
    "# buff_to_grayscale_image(image_buff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "235d1550-dfc5-4bb6-955b-577a8367f38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_dump_train_dataset_list = glob('/Users/timkh/Desktop/kisa/contest/grayscale_image/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efe60cc9-3bfa-4b16-a122-bb947cb6b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label = np.zeros(len(label))\n",
    "for i in range(len(label)):\n",
    "    class_label[i] = label['class'][i][:1]\n",
    "class_label = pd.DataFrame(class_label).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90e1a097-8f7a-4a50-be46-0acf22e1eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.Resize((100, 100)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0),(0.5))\n",
    "                           ])\n",
    "trainset = torchvision.datasets.ImageFolder( root=\"/Users/timkh/Desktop/kisa/contest/grayscale_class\", transform = trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf6624a1-8937-48ca-aba4-0ca8b70d0c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1_reconnaissance', '2_exploit', '3_post', '4_unknown']\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 50012\n",
      "    Root location: /Users/timkh/Desktop/kisa/contest/grayscale_class\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(100, 100), interpolation=bilinear, max_size=None, antialias=None)\n",
      "               ToTensor()\n",
      "               Normalize(mean=0, std=0.5)\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "classes = trainset.classes\n",
    "print(classes)\n",
    "print(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bc379ef-c78f-4b46-92ad-38dd2dc4e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(trainset))\n",
    "test_size = len(trainset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(trainset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8eb7c81b-0899-419a-a3e4-1ecfc4ca7dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc_layer): Sequential(\n",
      "    (0): Linear(in_features=6400, out_features=16, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(image_dump_train_dataset_list, class_label, test_size = 0.4, shuffle = True, random_state = 1004)\n",
    "\n",
    "batch_size = 16\n",
    "learning_rate = 1e-4\n",
    "num_epoch = 50\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=4,drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size,shuffle=False,num_workers=4,drop_last=True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.layer = nn.Sequential(\n",
    "      nn.Conv2d(3, 16, 3), \n",
    "      nn.MaxPool2d(2,2),\n",
    "      nn.Conv2d(16, 32, 3),\n",
    "      nn.MaxPool2d(2, 2),\n",
    "      nn.Conv2d(32, 64, 3),\n",
    "      nn.MaxPool2d(2, 2)\n",
    "    )\n",
    "    self.fc_layer = nn.Sequential(nn.Linear(6400,16))\n",
    "    \n",
    "  def forward(self, x):\n",
    "    # x = x.permute(0, \n",
    "    out = self.layer(x)\n",
    "    out = out.view(batch_size, -1)\n",
    "    out = self.fc_layer(out)\n",
    "    return out\n",
    "\n",
    "model = Net()\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr= learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1314d897-1083-4113-ab87-3d5a7bab1b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/torch/_tensor_str.py:103: UserWarning: The operator 'aten::bitwise_and.Tensor_out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  nonzero_finite_vals = torch.masked_select(tensor_view, torch.isfinite(tensor_view) & tensor_view.ne(0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7491, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4588, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6638, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1690, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0787, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0482, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1029, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0110, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3838, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2643, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0401, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0047, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6276, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0121, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1534, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0293, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0071, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0068, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0108, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0449, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2805, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2021, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0086, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0547, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0086, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0077, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0045, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0681, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0112, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0054, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0065, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0055, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0052, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0056, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0172, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0232, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0262, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2758, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0049, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1514, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0096, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0044, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0079, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0107, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0312, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0163, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0050, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0174, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0048, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0050, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0048, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0111, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0085, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0105, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0426, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0106, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0803, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0075, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0040, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0204, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0084, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(9.9873e-05, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0047, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0091, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2112, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0181, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0495, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0674, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0071, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0085, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0867, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0064, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0162, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1231, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0042, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2150, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0047, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0549, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1161, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0827, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0106, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0188, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0044, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0613, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "Accuracy of Test Data : 98.37000274658203\n"
     ]
    }
   ],
   "source": [
    "loss_arr = []\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    for j,[image,label] in enumerate(train_loader):\n",
    "        x = image\n",
    "        y_ = label\n",
    "\n",
    "        x = x.to(device)\n",
    "        y_ = y_.to(device)\n",
    "        \n",
    "        optimizer.zero_grad() #optimizer\n",
    "        output = model.forward(x) # CNN\n",
    "        loss = loss_func(output,y_)\n",
    "        loss.backward()#Back Propagation\n",
    "        optimizer.step()\n",
    "        if j % 1000 == 0 :\n",
    "            print(loss)\n",
    "            loss_arr.append(loss.cpu().detach().numpy())\n",
    "            \n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for image,label in test_loader : \n",
    "        x = image\n",
    "        y_ = label\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y_ = y_.to(device)\n",
    "        \n",
    "        output = model.forward(x)\n",
    "        _,output_index = torch.max(output,1)\n",
    "        total += label.size(0)\n",
    "        correct += (output_index == y_).sum().float()\n",
    "    print(\"Accuracy of Test Data : {}\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8c2ca33-4e94-4354-ac95-d1b0807722e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9837., device='mps:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c6c87ab-901e-4817-a032-0764995caa7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22d348b1-6b62-4a57-9eff-78d90be3eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchmetrics.classification import MulticlassPrecision\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "y_pred_list = []\n",
    "y_true_list = []\n",
    "with torch.no_grad():\n",
    "    for image,label in test_loader : \n",
    "        x = image.to(device)\n",
    "        # y_ = label\n",
    "        y_test_pred = model(x)\n",
    "        _, y_pred_tags = torch.max(y_test_pred, 1)\n",
    "        y_pred_list.append(y_pred_tags.cpu().numpy())\n",
    "        y_true_list.append(label.cpu().numpy())\n",
    "\n",
    "# y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "# y_true_list = [a.squeeze().tolist() for a in y_true_list]\n",
    "\n",
    "#         output = model.forward(x)\n",
    "#         _,output_index = torch.max(output,1)\n",
    "#         total += label.size(0)\n",
    "#         correct += (output_index == y_).sum().float()\n",
    "    # print(\"Accuracy of Test Data : {}\".format(100*correct/total))\n",
    "    # print(precision_score(y_true, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64134eb6-b5c1-4841-820f-3318a54c01f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9565)\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import AveragePrecision\n",
    "from torchmetrics.classification import MulticlassPrecision\n",
    "# from iterable import chain\n",
    "\n",
    "y_pred_list = torch.Tensor(np.array(y_pred_list).flatten())\n",
    "y_true_list = torch.Tensor(np.array(y_true_list).flatten())\n",
    "\n",
    "metrics = MulticlassPrecision(num_classes=4, average = 'macro')\n",
    "print(metrics(y_true_list, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad1f4339-6607-4716-8902-f38de189a003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc on clean (%) : 98.370\n",
      "test acc on FGM (%) : 1.340\n",
      "test acc on PGD (%) : 1.200\n"
     ]
    }
   ],
   "source": [
    "# cleverhans adversarial example add  \n",
    "# !pip3 install cleverhans\n",
    "# from absl import app, flags\n",
    "from cleverhans.torch.attacks.projected_gradient_descent import(\n",
    "    projected_gradient_descent, fast_gradient_method)\n",
    "from easydict import EasyDict\n",
    "\n",
    "# FLAGS = flags.FLAGS\n",
    "eps = 0.3 #epsilon\n",
    "nb_epochs = 8\n",
    "adv_train = False\n",
    "\n",
    "# flags.DEFINE_float(\"eps\", 0.3, \"Total epsilon for FGM and PGD attacks\")\n",
    "# flags.DEFINE_bool(\"adv_train\", False, \"User adversarial training on PGD adversarial examples\")\n",
    "\n",
    "# Evaluate on clean and adversarial data\n",
    "model.eval()\n",
    "report = EasyDict(nb_test=0, correct=0, correct_fgm=0, correct_pgd=0)\n",
    "\n",
    "for x, y in test_loader:\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    x_fgm = fast_gradient_method(model, x, eps, np.inf)\n",
    "    x_pgd = projected_gradient_descent(model, x, eps, 0.01, 40, np.inf)\n",
    "    _, y_pred = model(x).max(1) # pure\n",
    "    _, y_pred_fgm = model(x_fgm).max(1) # FGM adv example\n",
    "    _, y_pred_pgd = model(x_pgd).max(1) # PGD adv example\n",
    "    \n",
    "    report.nb_test += y.size(0)\n",
    "    report.correct += y_pred.eq(y).sum().item()\n",
    "    report.correct_fgm += y_pred_fgm.eq(y).sum().item()\n",
    "    report.correct_pgd += y_pred_pgd.eq(y).sum().item()\n",
    "\n",
    "print(\"test acc on clean (%) : {:.3f}\".format(report.correct / report.nb_test * 100.0))\n",
    "print(\"test acc on FGM (%) : {:.3f}\".format(report.correct_fgm / report.nb_test * 100.0))\n",
    "print(\"test acc on PGD (%) : {:.3f}\".format(report.correct_pgd / report.nb_test * 100.0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4c9731-d87d-4135-adf3-3da86588d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_arr = []\n",
    "\n",
    "# for i in range(num_epoch):\n",
    "#     for j,[image,label] in enumerate(train_loader):\n",
    "#         x = image\n",
    "#         y_ = label\n",
    "\n",
    "#         x = x.to(device)\n",
    "#         y_ = y_.to(device)\n",
    "        \n",
    "#         optimizer.zero_grad() #optimizer\n",
    "#         output = model.forward(x) # CNN\n",
    "#         loss = loss_func(output,y_)\n",
    "#         loss.backward()#Back Propagation\n",
    "#         optimizer.step()\n",
    "#         if j % 1000 == 0 :\n",
    "#             print(loss)\n",
    "#             loss_arr.append(loss.cpu().detach().numpy())\n",
    "            \n",
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for image,label in test_loader : \n",
    "#         x = image\n",
    "#         y_ = label\n",
    "        \n",
    "#         x = x.to(device)\n",
    "#         y_ = y_.to(device)\n",
    "        \n",
    "#         output = model.forward(x)\n",
    "#         _,output_index = torch.max(output,1)\n",
    "#         total += label.size(0)\n",
    "#         correct += (output_index == y_).sum().float()\n",
    "#     print(\"Accuracy of Test Data : {}\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c201e75f-1313-4247-84ee-39d80b67b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
